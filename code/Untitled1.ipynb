{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eb13920",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 使用 chunksize 分塊讀取第二個 CSV 檔案，逐步處理並寫入\u001b[39;00m\n\u001b[0;32m     12\u001b[0m chunksize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE:/專題/data/2021/PredictorDataAll.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, chunksize\u001b[38;5;241m=\u001b[39mchunksize):\n\u001b[0;32m     14\u001b[0m     chunk\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE:/專題/data/2021/PredictorDataAll.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m處理完成！\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1698\u001b[0m, in \u001b[0;36mTextFileReader.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m   1697\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1698\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_chunk()\n\u001b[0;32m   1699\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m   1700\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1810\u001b[0m, in \u001b[0;36mTextFileReader.get_chunk\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m   1808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m   1809\u001b[0m     size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnrows \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow)\n\u001b[1;32m-> 1810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nrows\u001b[38;5;241m=\u001b[39msize)\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1771\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m     (\n\u001b[0;32m   1775\u001b[0m         index,\n\u001b[0;32m   1776\u001b[0m         columns,\n\u001b[0;32m   1777\u001b[0m         col_dict,\n\u001b[1;32m-> 1778\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1779\u001b[0m         nrows\n\u001b[0;32m   1780\u001b[0m     )\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 230\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    232\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:820\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:890\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:1037\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:1083\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:1158\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\core\\dtypes\\common.py:1433\u001b[0m, in \u001b[0;36mis_extension_array_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;66;03m# Note: if other EA dtypes are ever held in HybridBlock, exclude those\u001b[39;00m\n\u001b[0;32m   1425\u001b[0m     \u001b[38;5;66;03m#  here too.\u001b[39;00m\n\u001b[0;32m   1426\u001b[0m     \u001b[38;5;66;03m# NB: need to check DatetimeTZDtype and not is_datetime64tz_dtype\u001b[39;00m\n\u001b[0;32m   1427\u001b[0m     \u001b[38;5;66;03m#  to exclude ArrowTimestampUSDtype\u001b[39;00m\n\u001b[0;32m   1428\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m   1429\u001b[0m         dtype, (DatetimeTZDtype, PeriodDtype)\n\u001b[0;32m   1430\u001b[0m     )\n\u001b[1;32m-> 1433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_extension_array_dtype\u001b[39m(arr_or_dtype) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m   1434\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1435\u001b[0m \u001b[38;5;124;03m    Check if an object is a pandas extension array type.\u001b[39;00m\n\u001b[0;32m   1436\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1476\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[0;32m   1477\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1478\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(arr_or_dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, arr_or_dtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 讀取第一個 CSV 檔案，假設其第一列的名子存放在第一列\n",
    "df1 = pd.read_excel('E:/專題/feature標籤值.xlsx', header=None)\n",
    "names = df1.iloc[0, :153].values  # 提取前153個名子\n",
    "\n",
    "# 創建一個新的 CSV 檔案，先寫入名子作為第一列\n",
    "with open('E:/專題/data/2021/PredictorDataAllWithLabel.csv', 'w', encoding='utf-8-sig') as f:\n",
    "    pd.DataFrame([names]).to_csv(f, header=False, index=False)\n",
    "\n",
    "# 使用 chunksize 分塊讀取第二個 CSV 檔案，逐步處理並寫入\n",
    "chunksize = 10000\n",
    "for chunk in pd.read_csv('E:/專題/data/2021/PredictorDataAll.csv', chunksize=chunksize):\n",
    "    chunk.to_csv('E:/專題/data/2021/PredictorDataAll.csv', mode='a', header=False, index=False)\n",
    "\n",
    "print(\"處理完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88214e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
