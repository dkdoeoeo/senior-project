{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f519e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2d1dba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "33bd0e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file_path, chunk_size):\n",
    "        self.file_path = file_path\n",
    "        self.chunk_size = chunk_size\n",
    "        \n",
    "        self.columns = pd.read_csv(self.file_path, nrows=0).columns.str.strip().str.replace('\\xa0', ' ').tolist()\n",
    "        self.train_columns = [col for col in self.columns if col != 'Discard']  # 排除 'Discard' 欄位\n",
    "        self.num_samples = sum(1 for _ in open(self.file_path, encoding='utf-8')) - 1  # 計算總樣本數\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        chunk_start = idx // self.chunk_size * self.chunk_size\n",
    "        df = pd.read_csv(self.file_path, skiprows=chunk_start + 1, nrows=self.chunk_size, header=None, encoding='utf-8')  # 跳過標題和之前的行\n",
    "\n",
    "        df.columns = self.columns\n",
    "        \n",
    "        # 確保 Reward 欄位存在\n",
    "        if 'Discard' not in df.columns:\n",
    "            raise KeyError(f\"Chunk starting at row {chunk_start + 1} does not contain 'Discard' column.\")\n",
    "        \n",
    "            \n",
    "        sample_idx = idx % self.chunk_size\n",
    "        \n",
    "        train_data = df[self.train_columns].iloc[sample_idx].values  # 提取除了 'Reward' 之外的欄位\n",
    "        \n",
    "        value_data = df['Discard'].iloc[sample_idx]  # 提取 'Reward' 欄位\n",
    "        \n",
    "        return torch.tensor(train_data, dtype=torch.float32), torch.tensor(value_data, dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5ad8262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "讀取csv\n",
    "\"\"\"\n",
    "file_path = 'E:/專題/data/2021/DiscardDataAll.csv'\n",
    "dataset = MyDataset(file_path, chunk_size=50000)  # 每次只加載 50000 行\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "10955f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    def __init__(self, num_layers=10):\n",
    "        super(MyCNN, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.conv_layers.append(nn.Conv1d(in_channels=1, out_channels=256, kernel_size=3, padding=1))\n",
    "        \n",
    "        for _ in range(1, num_layers - 1):\n",
    "            self.conv_layers.append(nn.Conv1d(in_channels=256, out_channels=256, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.conv_layers.append(nn.Conv1d(in_channels=256, out_channels=1, kernel_size=1, padding=0))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i, conv in enumerate(self.conv_layers):\n",
    "            if(i < len(self.conv_layers) - 1):\n",
    "                x = F.relu(conv(x))\n",
    "            else:\n",
    "                x = conv(x)\n",
    "        x = x.squeeze(1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a005776d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2827356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyCNN().to(device)\n",
    "loss_criterion  = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c630ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([28,  5, 31,  8,  2,  9, 17, 30, 16,  9, 17, 30, 16,  5, 29, 30, 19,  9,\n",
      "        17, 30, 25,  9, 32, 30, 31,  9, 17, 30, 16,  9, 29, 30, 25,  9, 17, 33,\n",
      "        16,  9, 17, 31, 31, 28, 28, 27, 31, 28, 28, 27, 31, 13, 28, 28, 10, 33,\n",
      "        31, 32, 32, 32, 10, 33, 31, 32,  2, 24], device='cuda:0')\n",
      "tensor([28,  2, 31, 23,  2, 28, 21, 23,  0,  0, 13, 13,  7, 18, 15, 15, 15, 26,\n",
      "         0, 30, 25, 10, 32, 25, 31,  7,  1, 25, 18, 15, 23,  7, 25,  5, 27, 27,\n",
      "        17, 13,  3, 29, 17, 29, 18, 17, 29,  8, 18, 31, 27, 27, 28, 31, 17, 27,\n",
      "         8, 26, 32, 13,  1, 33, 31, 21, 25, 19], device='cuda:0')\n",
      "Correct Predictions: 12\n",
      "Total Predictions: 64\n",
      "Accuracy: 0.1875\n",
      "At epoch: 0, loss: 3.387150764465332\n",
      "執行時間: 0.1093742847442627 秒\n"
     ]
    }
   ],
   "source": [
    "current_loss = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for train_data, value_data in train_dataloader:\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "        train_data = train_data.unsqueeze(1)\n",
    "        start_time = time.time()\n",
    "        train_data = train_data.to(device)\n",
    "        value_data = value_data.to(device)\n",
    "        output = model(train_data)\n",
    "        output = output.float()\n",
    "        value_data = value_data.long()\n",
    "        probabilities = F.softmax(output, dim=1)\n",
    "        \n",
    "        predicted_labels = torch.argmax(probabilities, dim=1)\n",
    "        correct_predictions = (predicted_labels == value_data).sum().item()\n",
    "        accuracy = correct_predictions / value_data.size(0)\n",
    "        \n",
    "        loss = loss_criterion(probabilities, value_data)\n",
    "        \n",
    "        current_loss = loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        clear_output()\n",
    "        end_time = time.time()\n",
    "        print(predicted_labels)\n",
    "        print(value_data)\n",
    "        print(f\"Correct Predictions: {correct_predictions}\")\n",
    "        print(f\"Total Predictions: {value_data.size(0)}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"At epoch: {epoch}, loss: {current_loss}\")\n",
    "        print(f\"執行時間: {end_time - start_time} 秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42599ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
