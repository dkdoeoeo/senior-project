{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "best_accuracy = 50\n",
    "#num_layers = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file_path, chunk_size):\n",
    "        self.file_path = file_path\n",
    "        self.chunk_size = chunk_size\n",
    "        \n",
    "        self.columns = pd.read_csv(self.file_path, nrows=0).columns.str.strip().str.replace('\\xa0', ' ').tolist()\n",
    "        self.train_columns = [col for col in self.columns if col != 'If Chow']  # 排除 'If Chow' 欄位\n",
    "        self.num_samples = sum(1 for _ in open(self.file_path, encoding='utf-8')) - 1  # 計算總樣本數\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        chunk_start = idx // self.chunk_size * self.chunk_size\n",
    "        df = pd.read_csv(self.file_path, skiprows=chunk_start + 1, nrows=self.chunk_size, header=None, encoding='utf-8')  # 跳過標題和之前的行\n",
    "\n",
    "        df.columns = self.columns\n",
    "        \n",
    "        if 'If Chow' not in df.columns:\n",
    "            raise KeyError(f\"Chunk starting at row {chunk_start + 1} does not contain 'If Chow' column.\")\n",
    "        \n",
    "            \n",
    "        sample_idx = idx % self.chunk_size\n",
    "        \n",
    "        train_data = df[self.train_columns].iloc[sample_idx].values\n",
    "        \n",
    "        value_data = df['If Chow'].iloc[sample_idx]  # 提取 'If Chow' 欄位\n",
    "        \n",
    "        return torch.tensor(train_data, dtype=torch.float32), torch.tensor(value_data, dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "讀取csv\n",
    "\"\"\"\n",
    "file_path = 'E:/專題/data/2020/ChowData.csv'\n",
    "dataset = MyDataset(file_path, chunk_size=50000)  # 每次只加載 50000 行\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    def __init__(self, num_layers = 10, input_features=153, output_features=1):\n",
    "        super(MyCNN, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.conv_layers.append(nn.Conv1d(in_channels=1, out_channels=256, kernel_size=3, padding=1))\n",
    "        \n",
    "        for _ in range(1, num_layers - 1):\n",
    "            self.conv_layers.append(nn.Conv1d(in_channels=256, out_channels=256, kernel_size=3, padding=1))\n",
    "        \n",
    "        self.conv_layers.append(nn.Conv1d(in_channels=256, out_channels=1, kernel_size=1, padding=0))\n",
    "        \n",
    "        self.activation = nn.LeakyReLU(negative_slope=0.01)\n",
    "\n",
    "        self.fc = nn.Linear(input_features, output_features)\n",
    "    def forward(self, x):\n",
    "        #x = x.unsqueeze(-1)\n",
    "\n",
    "        for i, conv in enumerate(self.conv_layers):\n",
    "            if(i < len(self.conv_layers) - 1):\n",
    "                x = self.activation(conv(x))\n",
    "            else:\n",
    "                x = conv(x)\n",
    "        x = x.squeeze(1)\n",
    "        x = self.fc(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        print(\"x.shape:\",x.shape)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyCNN().to(device)\n",
    "loss_criterion = nn.BCELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0.],\n",
      "       device='cuda:0')\n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.],\n",
      "       device='cuda:0')\n",
      "Correct Predictions: 17\n",
      "Total Predictions: 32\n",
      "Accuracy: 53.1250 %\n",
      "At epoch: 0, loss: 0.7034590840339661\n",
      "best accuracy: 78.125\n",
      "conv_layers.0.weight gradient norm: 0.004354724194854498\n",
      "conv_layers.0.bias gradient norm: 0.0037471081595867872\n",
      "conv_layers.1.weight gradient norm: 0.011790306307375431\n",
      "conv_layers.1.bias gradient norm: 0.0012808378087356687\n",
      "conv_layers.2.weight gradient norm: 0.018024791032075882\n",
      "conv_layers.2.bias gradient norm: 0.0018955487757921219\n",
      "conv_layers.3.weight gradient norm: 0.017486615106463432\n",
      "conv_layers.3.bias gradient norm: 0.004660176578909159\n",
      "conv_layers.4.weight gradient norm: 0.011519890278577805\n",
      "conv_layers.4.bias gradient norm: 0.0069564757868647575\n",
      "conv_layers.5.weight gradient norm: 0.00920488778501749\n",
      "conv_layers.5.bias gradient norm: 0.008381539024412632\n",
      "conv_layers.6.weight gradient norm: 0.016107508912682533\n",
      "conv_layers.6.bias gradient norm: 0.01662607677280903\n",
      "conv_layers.7.weight gradient norm: 0.009188146330416203\n",
      "conv_layers.7.bias gradient norm: 0.02153491973876953\n",
      "conv_layers.8.weight gradient norm: 0.009565903805196285\n",
      "conv_layers.8.bias gradient norm: 0.01242089830338955\n",
      "conv_layers.9.weight gradient norm: 0.06872041523456573\n",
      "conv_layers.9.bias gradient norm: 0.008755652233958244\n",
      "fc.weight gradient norm: 0.13419903814792633\n",
      "fc.bias gradient norm: 0.004487164318561554\n"
     ]
    }
   ],
   "source": [
    "current_loss = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for train_data, value_data in train_dataloader:\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "        channel1_tensor = train_data.unsqueeze(1).to(device)\n",
    "        value_data = value_data.to(device).float()\n",
    "        \n",
    "        output = model(channel1_tensor).squeeze(1)\n",
    "\n",
    "        loss = loss_criterion(output, value_data)\n",
    "        current_loss = loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        clear_output()\n",
    "        predicted_labels = (output > 0.5).float()\n",
    "        correct_predictions = (predicted_labels == value_data).sum().item()\n",
    "        accuracy = (correct_predictions / value_data.size(0)) * 100\n",
    "        print(predicted_labels)\n",
    "        print(value_data)\n",
    "        print(f\"Correct Predictions: {correct_predictions}\")\n",
    "        print(f\"Total Predictions: {value_data.size(0)}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\",\"%\")\n",
    "        print(f\"At epoch: {epoch}, loss: {current_loss}\")\n",
    "        print(f\"best accuracy: {best_accuracy}\")\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                print(f'{name} gradient norm: {param.grad.norm()}')\n",
    "        \n",
    "        if accuracy >= best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            torch.save(model, f'E:/專題/chow_model/CNN_chow_model_{best_accuracy}.pth')\n",
    "            print(f'模型在 epoch {epoch} 之後被儲存，正確率: {best_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
